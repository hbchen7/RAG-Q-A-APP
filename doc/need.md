RAG-知识库问答系统

# 功能板块、技术板块

## LLM 对话功能

## 知识库问答功能

### 知识库创建、上传文件、编辑、删除 ———— 技术细节：知识向量化存储

# 用户故事、背景、需求背景

大语言模型(后简称 LLM)是一种基于深度学习技术的自然语言处理模型，它能够理解、生成、推理和扩展文本。它可以帮助用户快速理解文本信息，并根据用户的需求生成相应的答案，它的诞生促进了新一轮的生产力解放。越来越多的人尝试将 LLM 技术应用于日常生活，而当人们将 LLM 应用于实际业务场景时会发现，通用的基础大模型基本无法满足我们的实际需求，主要有以下几方面原因:

1. LLM 的知识不是实时的，不具备知识更新的能力。
2. LLM 可能不知道你私有的领域、业务知识，无法回答私人问题。
3. LLM 有时会在回答中生成看似合理但实际上是错误的信息，这就是典型的"幻觉"现象。

为了解决以上问题 RAG 由此诞生，RAG 即 Retrival-Augmented Generation，是一种基于检索技术的对话系统，它可以帮助用户快速理解文本信息，并根据用户的需求生成相应的答案。RAG 具有以下优势:

1. 提高准确性: 通过检索相关的信息，RAG 可以提高生成文本的准确性。
2. 减少训练成本：与需要大量数据来训练大模型的微调技术相比，RAG 可以通过检索机制来减少所需的训练数据量，从而降低训练成本。
3. 适应性强：RAG 模型可以适应新的或不断变化的数据。由于它们能够检索最新的信息，因此在新数据和事件出现时，它们能够快速适应并生成相关的文本。

## 目标用户

### to B

企业，企业通过在本地部署大模型后，应用本项目，就形成一套完全本地化的知识库问答系统，保证了企业资料的安全性和隐私性，为企业提供知识库问答服务，提高企业生产力。

### to C

个人，个人通过本项目，可以打造属于自己的知识库，快速获取相关的知识，提高个人能力，让 AI 技术赋能生活与工作。

# case 场景

用户打开应用，可用管理员账号登录或注册新账号再进行登录，进入知识库问答页面。
用户首先可以选择一个助手，创建一个属于该助手的新的会话，进入会话页面。
接着用户可以选择大语言模型和知识库，并输入问题，系统会检索知识库，再进由大语言模型生成答案，回显在聊天框中。

## 知识库管理

用户可以上传自己的知识库文件，编辑和删除。

## 助手

用户可以创建自定义助手，为助手设定提示词、为助手自定义名称

## 会话

用户可以在一个助手下，创建多个独立的会话，

## 问答

在会话页面中，用户可以输入问题，选择大语言模型和知识库，系统会检索知识库，再由大语言模型生成答案，回显在聊天框中。
用户还可以调节更多的配置，在输入框区域中，可以更换大语言模型、更换知识库、快捷添加提示词，选择是否联网搜索等。
以及在设置选项卡中调节模型温度、模型上下文条数等。
