import logging
import os  # æ·»åŠ  os æ¨¡å—å¯¼å…¥
from typing import Iterable, Optional

from dotenv import load_dotenv
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain.chains.retrieval import create_retrieval_chain
from langchain_core.chat_history import BaseChatMessageHistory  # å¯¼å…¥åŸºç±»
from langchain_core.messages import AIMessageChunk
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import (  # å¯¼å…¥ ConfigurableFieldSpec
    AddableDict,
    ConfigurableFieldSpec,
)
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_core.runnables.utils import Output

# ç§»é™¤å†…å­˜å†å²è®°å½•çš„å¯¼å…¥
# from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_mongodb.chat_message_histories import (
    MongoDBChatMessageHistory,  # å¯¼å…¥ MongoDB å†å²è®°å½•
)

from src.utils.Knowledge import Knowledge

# utils
from src.utils.llm_modle import get_llms

load_dotenv()


class ChatSev:
    # ç§»é™¤ç±»çº§åˆ«çš„å†…å­˜å†å²è®°å½•å®ä¾‹
    # _chat_history = ChatMessageHistory()  # å¯¹è¯å†å²

    def __init__(
        self,
        knowledge: Optional[Knowledge] = None,
        chat_history_max_length: Optional[int] = 8,
    ):
        self.knowledge: Optional[Knowledge] = knowledge
        # chat_history_max_length å¯¹äºæ•°æ®åº“å­˜å‚¨å¯èƒ½ä¸å†ç›´æ¥ç›¸å…³ï¼Œä½†ä¿ç•™ä»¥å¤‡å°†æ¥ä½¿ç”¨
        self.chat_history_max_length: int = (
            chat_history_max_length if chat_history_max_length is not None else 8
        )

        # ä»ç¯å¢ƒå˜é‡è¯»å– MongoDB é…ç½®
        self.mongo_connection_string = os.getenv(
            "MONGO_URI", "mongodb://localhost:27017/"
        )
        self.mongo_database_name = os.getenv("MONGO_DB_NAME", "fastapi")
        # ä½¿ç”¨ .env ä¸­å®šä¹‰çš„é›†åˆåç§°
        self.mongo_collection_name = os.getenv(
            "MONGODB_COLLECTION_NAME_CHATHISTORY", "chatHistoy"
        )  # ä¿®æ”¹ä¸º chatHistoy

        self.knowledge_prompt = None  # é—®ç­”æ¨¡æ¿
        self.normal_prompt = None  # æ­£å¸¸æ¨¡æ¿
        self.create_chat_prompt()  # åˆ›å»ºèŠå¤©æ¨¡æ¿

    def create_chat_prompt(self) -> None:
        ai_info = "ä½ å«è¶…çº§æ— æ•Œéœ¸ç‹é¾™ğŸ¦–ï¼Œä¸€ä¸ªå¸®åŠ©äººä»¬è§£ç­”å„ç§é—®é¢˜çš„åŠ©æ‰‹ã€‚"

        # AIç³»ç»Ÿprompt
        knowledge_system_prompt = (
            f"{ai_info} å½“ç”¨æˆ·å‘ä½ æé—®ï¼Œè¯·ä½ ä½¿ç”¨ä¸‹é¢æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡æ¥å›ç­”é—®é¢˜ã€‚å¦‚æœæ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡ä¸­æ²¡æœ‰é—®é¢˜çš„ç­”æ¡ˆï¼Œè¯·ä½ ç›´æ¥å›ç­”ä¸çŸ¥é“ã€‚æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡å¦‚ä¸‹ï¼š\n\n"
            "{context}"
        )

        self.knowledge_prompt = ChatPromptTemplate.from_messages(  # çŸ¥è¯†åº“prompt
            [
                ("system", knowledge_system_prompt),
                ("placeholder", "{chat_history}"),
                ("human", "{input}"),
            ]
        )

        # æ²¡æœ‰æŒ‡å®šçŸ¥è¯†åº“çš„æ¨¡æ¿çš„AIç³»ç»Ÿæ¨¡æ¿
        self.normal_prompt = ChatPromptTemplate.from_messages(  # æ­£å¸¸prompt
            [
                ("system", ai_info),
                ("placeholder", "{chat_history}"),
                ("human", "{input}"),
            ]
        )

    @staticmethod
    def streaming_parse(chunks: Iterable[AIMessageChunk]) -> list[AddableDict]:
        """ç»Ÿä¸€æ¨¡å‹çš„è¾“å‡ºæ ¼å¼ï¼Œå°†æ¨¡å‹çš„è¾“å‡ºå­˜å‚¨åˆ°å­—å…¸answerçš„valueä¸­"""
        for chunk in chunks:
            yield AddableDict({"answer": chunk.content})

    def get_chain(
        self,
        api_key: Optional[str],
        collection: str,
        supplier: str,
        model: str,
        max_length: int,
        temperature: float = 0.8,
    ) -> RunnableWithMessageHistory:
        """è·å–èŠå¤©é“¾"""
        chat = get_llms(
            supplier=supplier,
            model=model,
            api_key=api_key,
            max_length=max_length,
            temperature=temperature,
        )

        # ç»Ÿä¸€è¿”å›é€»è¾‘
        rag_chain = (
            self.normal_prompt | chat | self.streaming_parse
            if collection is None
            else create_retrieval_chain(
                self.knowledge.get_retrievers(collection),
                create_stuff_documents_chain(chat, self.knowledge_prompt),
            )
        )
        # ç§»é™¤å¯¹ç±»çº§åˆ« _chat_history çš„è®¿é—®
        # logging.info("Chat history content: %s", self._chat_history.messages)

        # ä½¿ç”¨ RunnableWithMessageHistory å¹¶é…ç½® MongoDB å†å²è®°å½•
        chain_with_history = RunnableWithMessageHistory(
            rag_chain,
            self.get_session_chat_history,  # ä¼ é€’æ–¹æ³•å¼•ç”¨
            input_messages_key="input",
            history_messages_key="chat_history",
            output_messages_key="answer",
            # é…ç½® session_id ä½œä¸ºå¯é…ç½®å­—æ®µ
            history_factory_config=[
                ConfigurableFieldSpec(
                    id="session_id",
                    annotation=str,
                    name="Session ID",
                    description="Unique identifier for the chat session.",
                    default="default_session",  # æä¾›ä¸€ä¸ªé»˜è®¤å€¼ä»¥é˜²ä¸‡ä¸€
                    is_shared=True,
                )
            ],
        )
        return chain_with_history

    def get_session_chat_history(self, session_id: str) -> BaseChatMessageHistory:
        """æ ¹æ® session_id è·å– MongoDB èŠå¤©è®°å½•å®ä¾‹"""
        logging.info(f"è·å– session_id ä¸º {session_id} çš„ MongoDB èŠå¤©è®°å½•")
        return MongoDBChatMessageHistory(
            connection_string=self.mongo_connection_string,
            session_id=session_id,
            database_name=self.mongo_database_name,
            collection_name=self.mongo_collection_name,
        )

    def invoke(
        self,
        question: str,
        api_key: Optional[str],
        collection: Optional[str],
        supplier: str,
        model: str,
        session_id: str,  # æ·»åŠ  session_id å‚æ•°
        max_length=None,
        temperature=0.8,
    ) -> Output:
        """
        :param question: ç”¨æˆ·æå‡ºçš„é—®é¢˜ ä¾‹å¦‚: 'è¯·é—®ä½ æ˜¯è°ï¼Ÿ'
        :param collection: çŸ¥è¯†åº“æ–‡ä»¶åç§° ä¾‹å¦‚:'äººäº‹ç®¡ç†æµç¨‹.docx'
        :param model: ä½¿ç”¨æ¨¡å‹,é»˜è®¤ä¸º 'gpt-3.5-turbo'
        :param max_length: æ•°æ®è¿”å›æœ€å¤§é•¿åº¦
        :param temperature: æ•°æ®æ¸©åº¦å€¼
        :param session_id: ç”¨äºåŒºåˆ†ä¸åŒèŠå¤©ä¼šè¯çš„å”¯ä¸€æ ‡è¯†ç¬¦
        """
        # ç§»é™¤å¯¹ç±»çº§åˆ« _chat_history çš„è®¿é—®
        # logging.info("Chat history content: %s", self._chat_history.messages)

        # è·å–é…ç½®å¥½çš„é“¾
        chain = self.get_chain(
            api_key, collection, supplier, model, max_length, temperature
        )
        # åˆ›å»ºé…ç½®å­—å…¸ï¼Œå°† session_id ä¼ é€’ç»™ RunnableWithMessageHistory
        config = {"configurable": {"session_id": session_id}}
        logging.info(f"ä½¿ç”¨ session_id: {session_id} è°ƒç”¨èŠå¤©é“¾")
        # è°ƒç”¨é“¾å¹¶ä¼ å…¥é—®é¢˜å’Œé…ç½®
        return chain.invoke({"input": question}, config=config)

    def clear_history(self, session_id: str) -> None:
        """æ¸…é™¤æŒ‡å®š session_id çš„å†å²ä¿¡æ¯"""
        # è·å–å¯¹åº” session_id çš„å†å²è®°å½•å¯¹è±¡
        history = self.get_session_chat_history(session_id)
        # è°ƒç”¨å…¶ clear æ–¹æ³•
        history.clear()
        logging.info(f"å·²æ¸…é™¤ session_id ä¸º {session_id} çš„ MongoDB å†å²è®°å½•")

    def get_history_message(self, session_id: str) -> list:
        """è·å–æŒ‡å®š session_id çš„å†å²ä¿¡æ¯"""
        # è·å–å¯¹åº” session_id çš„å†å²è®°å½•å¯¹è±¡
        history = self.get_session_chat_history(session_id)
        logging.info(f"è·å– session_id ä¸º {session_id} çš„ MongoDB å†å²æ¶ˆæ¯")
        # è¿”å›å…¶ messages å±æ€§
        return history.messages
